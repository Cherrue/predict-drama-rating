{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TH-home\\AppData\\Local\\conda\\conda\\envs\\my_root\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2017-08-09 17:04:00,409 : INFO : collecting all words and their counts\n",
      "2017-08-09 17:04:00,410 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-08-09 17:04:00,411 : INFO : collected 3 word types from a corpus of 4 raw words and 2 sentences\n",
      "2017-08-09 17:04:00,412 : INFO : Loading a fresh vocabulary\n",
      "2017-08-09 17:04:00,413 : INFO : min_count=1 retains 3 unique words (100% of original 3, drops 0)\n",
      "2017-08-09 17:04:00,414 : INFO : min_count=1 leaves 4 word corpus (100% of original 4, drops 0)\n",
      "2017-08-09 17:04:00,415 : INFO : deleting the raw counts dictionary of 3 items\n",
      "2017-08-09 17:04:00,416 : INFO : sample=0.001 downsamples 3 most-common words\n",
      "2017-08-09 17:04:00,417 : INFO : downsampling leaves estimated 0 word corpus (5.7% of prior 4)\n",
      "2017-08-09 17:04:00,418 : INFO : estimated required memory for 3 words and 100 dimensions: 3900 bytes\n",
      "2017-08-09 17:04:00,419 : INFO : resetting layer weights\n",
      "2017-08-09 17:04:00,421 : INFO : training model with 3 workers on 3 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-08-09 17:04:00,425 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-08-09 17:04:00,426 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-08-09 17:04:00,426 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-08-09 17:04:00,427 : INFO : training on 20 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2017-08-09 17:04:00,429 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "import gensim,logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "                   level=logging.INFO)\n",
    " \n",
    "sentences = [['first', 'sentence'], ['second', 'sentence']]\n",
    "# train word2vec on the two sentences\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-09 17:04:01,252 : INFO : collecting all words and their counts\n",
      "2017-08-09 17:04:01,254 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-08-09 17:04:01,257 : INFO : collected 358 word types from a corpus of 861 raw words and 152 sentences\n",
      "2017-08-09 17:04:01,258 : INFO : Loading a fresh vocabulary\n",
      "2017-08-09 17:04:01,260 : INFO : min_count=5 retains 31 unique words (8% of original 358, drops 327)\n",
      "2017-08-09 17:04:01,262 : INFO : min_count=5 leaves 379 word corpus (44% of original 861, drops 482)\n",
      "2017-08-09 17:04:01,263 : INFO : deleting the raw counts dictionary of 358 items\n",
      "2017-08-09 17:04:01,264 : INFO : sample=0.001 downsamples 31 most-common words\n",
      "2017-08-09 17:04:01,265 : INFO : downsampling leaves estimated 73 word corpus (19.4% of prior 379)\n",
      "2017-08-09 17:04:01,266 : INFO : estimated required memory for 31 words and 100 dimensions: 40300 bytes\n",
      "2017-08-09 17:04:01,268 : INFO : resetting layer weights\n",
      "2017-08-09 17:04:01,270 : INFO : training model with 3 workers on 31 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-08-09 17:04:01,282 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-08-09 17:04:01,283 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-08-09 17:04:01,284 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-08-09 17:04:01,286 : INFO : training on 4305 raw words (361 effective words) took 0.0s, 30573 effective words/s\n",
      "2017-08-09 17:04:01,286 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MySentences object at 0x000001D7B784B6A0>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            try:\n",
    "                for line in open(os.path.join(self.dirname, fname)):\n",
    "                    yield line.split()\n",
    "            except:\n",
    "                pass\n",
    "sentences= MySentences(os.getcwd()) # a memory-friendly iterator\n",
    "print(sentences)\n",
    "model = gensim.models.Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-09 17:07:24,409 : INFO : collecting all words and their counts\n",
      "2017-08-09 17:07:24,410 : WARNING : Each 'sentences' item should be a list of words (usually unicode strings).First item here is instead plain <class 'str'>.\n",
      "2017-08-09 17:07:24,411 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-08-09 17:07:24,412 : INFO : collected 5 word types from a corpus of 8 raw words and 8 sentences\n",
      "2017-08-09 17:07:24,413 : INFO : Loading a fresh vocabulary\n",
      "2017-08-09 17:07:24,414 : INFO : min_count=1 retains 5 unique words (100% of original 5, drops 0)\n",
      "2017-08-09 17:07:24,414 : INFO : min_count=1 leaves 8 word corpus (100% of original 8, drops 0)\n",
      "2017-08-09 17:07:24,416 : INFO : deleting the raw counts dictionary of 5 items\n",
      "2017-08-09 17:07:24,416 : INFO : sample=0.001 downsamples 5 most-common words\n",
      "2017-08-09 17:07:24,417 : INFO : downsampling leaves estimated 0 word corpus (7.2% of prior 8)\n",
      "2017-08-09 17:07:24,418 : INFO : estimated required memory for 5 words and 100 dimensions: 6500 bytes\n",
      "2017-08-09 17:07:24,419 : INFO : resetting layer weights\n",
      "2017-08-09 17:07:24,421 : INFO : training model with 3 workers on 5 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-08-09 17:07:24,426 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-08-09 17:07:24,427 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-08-09 17:07:24,428 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-08-09 17:07:24,429 : INFO : training on 40 raw words (3 effective words) took 0.0s, 785 effective words/s\n",
      "2017-08-09 17:07:24,431 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MySentences object at 0x000001D7B7850128>\n"
     ]
    }
   ],
   "source": [
    "sentences= MySentences(os.getcwd()) # a memory-friendly iterator\n",
    "print(sentences)\n",
    "model = gensim.models.Word2Vec(\"test.txt\",min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "missing section header before line #0 in test.txt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-49a5c0830555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\TH-home\\AppData\\Local\\conda\\conda\\envs\\my_root\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(self, questions, restrict_vocab, most_similar, case_insensitive)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmost_similar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase_insensitive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0mmost_similar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmost_similar\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmost_similar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase_insensitive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\TH-home\\AppData\\Local\\conda\\conda\\envs\\my_root\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(self, questions, restrict_vocab, most_similar, case_insensitive)\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msection\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"missing section header before line #%i in %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline_no\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mcase_insensitive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: missing section header before line #0 in test.txt"
     ]
    }
   ],
   "source": [
    "model.accuracy('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-09 17:10:53,647 : INFO : saving Word2Vec object under mymodel, separately None\n",
      "2017-08-09 17:10:53,649 : INFO : not storing attribute syn0norm\n",
      "2017-08-09 17:10:53,650 : INFO : not storing attribute cum_table\n",
      "2017-08-09 17:10:53,655 : INFO : saved mymodel\n",
      "2017-08-09 17:10:53,657 : INFO : loading Word2Vec object from mymodel\n",
      "2017-08-09 17:10:53,659 : INFO : loading wv recursively from mymodel.wv.* with mmap=None\n",
      "2017-08-09 17:10:53,660 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-08-09 17:10:53,662 : INFO : setting ignored attribute cum_table to None\n",
      "2017-08-09 17:10:53,663 : INFO : loaded mymodel\n"
     ]
    }
   ],
   "source": [
    "model.save('mymodel')\n",
    "new_model = gensim.models.Word2Vec.load('mymodel')\n",
    "#also can\n",
    "#model = Word2Vec.load_word2vec_format('/tmp/vectors.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add train\n",
    "#model.train(more_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "model.doesnt_match(\"breakfast cereal dinner lunch\";.split())\n",
    "# get similarity\n",
    "model.similarity('woman', 'man')\n",
    "# get vector\n",
    "model['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asdf']\n",
      "['asdfasdf']\n",
      "['asdfasdfasdf']\n",
      "['asdfasdfasdfasdf']\n",
      "['{']\n",
      "['\"cells\":', '[']\n",
      "['{']\n",
      "['\"cell_type\":', '\"code\",']\n",
      "['\"execution_count\":', '1,']\n",
      "['\"metadata\":', '{']\n",
      "['\"collapsed\":', 'false,']\n",
      "['\"scrolled\":', 'false']\n",
      "['},']\n",
      "['\"outputs\":', '[']\n",
      "['{']\n",
      "['\"name\":', '\"stderr\",']\n",
      "['\"output_type\":', '\"stream\",']\n",
      "['\"text\":', '[']\n",
      "['\"C:\\\\\\\\Users\\\\\\\\TH-home\\\\\\\\AppData\\\\\\\\Local\\\\\\\\conda\\\\\\\\conda\\\\\\\\envs\\\\\\\\my_root\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\gensim\\\\\\\\utils.py:865:', 'UserWarning:', 'detected', 'Windows;', 'aliasing', 'chunkize', 'to', 'chunkize_serial\\\\n\",']\n",
      "['\"', 'warnings.warn(\\\\\"detected', 'Windows;', 'aliasing', 'chunkize', 'to', 'chunkize_serial\\\\\")\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,409', ':', 'INFO', ':', 'collecting', 'all', 'words', 'and', 'their', 'counts\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,410', ':', 'INFO', ':', 'PROGRESS:', 'at', 'sentence', '#0,', 'processed', '0', 'words,', 'keeping', '0', 'word', 'types\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,411', ':', 'INFO', ':', 'collected', '3', 'word', 'types', 'from', 'a', 'corpus', 'of', '4', 'raw', 'words', 'and', '2', 'sentences\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,412', ':', 'INFO', ':', 'Loading', 'a', 'fresh', 'vocabulary\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,413', ':', 'INFO', ':', 'min_count=1', 'retains', '3', 'unique', 'words', '(100%', 'of', 'original', '3,', 'drops', '0)\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,414', ':', 'INFO', ':', 'min_count=1', 'leaves', '4', 'word', 'corpus', '(100%', 'of', 'original', '4,', 'drops', '0)\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,415', ':', 'INFO', ':', 'deleting', 'the', 'raw', 'counts', 'dictionary', 'of', '3', 'items\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,416', ':', 'INFO', ':', 'sample=0.001', 'downsamples', '3', 'most-common', 'words\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,417', ':', 'INFO', ':', 'downsampling', 'leaves', 'estimated', '0', 'word', 'corpus', '(5.7%', 'of', 'prior', '4)\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,418', ':', 'INFO', ':', 'estimated', 'required', 'memory', 'for', '3', 'words', 'and', '100', 'dimensions:', '3900', 'bytes\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,419', ':', 'INFO', ':', 'resetting', 'layer', 'weights\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,421', ':', 'INFO', ':', 'training', 'model', 'with', '3', 'workers', 'on', '3', 'vocabulary', 'and', '100', 'features,', 'using', 'sg=0', 'hs=0', 'sample=0.001', 'negative=5', 'window=5\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,425', ':', 'INFO', ':', 'worker', 'thread', 'finished;', 'awaiting', 'finish', 'of', '2', 'more', 'threads\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,426', ':', 'INFO', ':', 'worker', 'thread', 'finished;', 'awaiting', 'finish', 'of', '1', 'more', 'threads\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,426', ':', 'INFO', ':', 'worker', 'thread', 'finished;', 'awaiting', 'finish', 'of', '0', 'more', 'threads\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,427', ':', 'INFO', ':', 'training', 'on', '20', 'raw', 'words', '(0', 'effective', 'words)', 'took', '0.0s,', '0', 'effective', 'words/s\\\\n\",']\n",
      "['\"2017-08-09', '17:04:00,429', ':', 'WARNING', ':', 'under', '10', 'jobs', 'per', 'worker:', 'consider', 'setting', 'a', 'smaller', \"`batch_words'\", 'for', 'smoother', 'alpha', 'decay\\\\n\"']\n",
      "[']']\n",
      "['}']\n",
      "['],']\n",
      "['\"source\":', '[']\n",
      "['\"import', 'gensim,logging\\\\n\",']\n",
      "['\"logging.basicConfig(format=\\'%(asctime)s', ':', '%(levelname)s', ':', '%(message)s\\',\\\\\\\\\\\\n\",']\n",
      "['\"', 'level=logging.INFO)\\\\n\",']\n",
      "['\"', '\\\\n\",']\n",
      "['\"sentences', '=', \"[['first',\", \"'sentence'],\", \"['second',\", '\\'sentence\\']]\\\\n\",']\n",
      "['\"#', 'train', 'word2vec', 'on', 'the', 'two', 'sentences\\\\n\",']\n",
      "['\"model', '=', 'gensim.models.Word2Vec(sentences,', 'min_count=1)\"']\n",
      "[']']\n",
      "['},']\n",
      "['{']\n",
      "['\"cell_type\":', '\"code\",']\n",
      "['\"execution_count\":', '2,']\n",
      "['\"metadata\":', '{']\n",
      "['\"collapsed\":', 'false']\n",
      "['},']\n",
      "['\"outputs\":', '[']\n",
      "['{']\n",
      "['\"name\":', '\"stderr\",']\n",
      "['\"output_type\":', '\"stream\",']\n",
      "['\"text\":', '[']\n",
      "['\"2017-08-09', '17:04:01,252', ':', 'INFO', ':', 'collecting', 'all', 'words', 'and', 'their', 'counts\\\\n\",']\n",
      "['\"2017-08-09', '17:04:01,254', ':', 'INFO', ':', 'PROGRESS:', 'at', 'sentence', '#0,', 'processed', '0', 'words,', 'keeping', '0', 'word', 'types\\\\n\",']\n",
      "['\"2017-08-09', '17:04:01,257', ':', 'INFO', ':', 'collected', '358', 'word', 'types', 'from', 'a', 'corpus', 'of', '861', 'raw', 'words', 'and', '152', 'sentences\\\\n\",']\n",
      "['\"2017-08-09', '17:04:01,258', ':', 'INFO', ':', 'Loading', 'a', 'fresh', 'vocabulary\\\\n\",']\n",
      "['\"2017-08-09', '17:04:01,260', ':', 'INFO', ':', 'min_count=5', 'retains', '31', 'unique', 'words', '(8%', 'of', 'original', '358,', 'drops', '327)\\\\n\",']\n",
      "['\"2017-08-09', '17:04:01,262', ':', 'INFO', ':', 'min_count=5', 'leaves', '379', 'word', 'corpus', '(44%', 'of', 'original', '861,', 'drops', '482)\\\\n\",']\n",
      "['\"2017-08-09', '17:04:01,263', ':', 'INFO', ':', 'deleting', 'the', 'raw', 'counts', 'dictionary', 'of', '358', 'items\\\\n\",']\n",
      "['\"2017-08-09', '17:04:01,264', ':', 'INFO', ':', 'sample=0.001', 'downsamples', '31', 'most-common', 'words\\\\n\",']\n",
      "['\"2017-08-09', '17:04:01,265', ':', 'INFO', ':', 'downsampling', 'leaves', 'estimated', '73', 'word', 'corpus', '(19.4%', 'of', 'prior', '379)\\\\n\",']\n",
      "['\"2017-08-09', '17:04:01,266', ':', 'INFO', ':', 'estimated', 'required', 'memory', 'for', '31', 'words', 'and', '100', 'dimensions:', '40300', 'bytes\\\\n\",']\n",
      "['\"2017-08-09', '17:04:01,268', ':', 'INFO', ':', 'resetting', 'layer', 'weights\\\\n\",']\n",
      "['\"2017-08-09', '17:04:01,270', ':', 'INFO', ':', 'training', 'model', 'with', '3', 'workers', 'on', '31', 'vocabulary', 'and', '100', 'features,', 'using', 'sg=0', 'hs=0', 'sample=0.001', 'negative=5', 'window=5\\\\n\",']\n",
      "['\"2017-08-09', '17:04:01,282', ':', 'INFO', ':', 'worker', 'thread', 'finished;', 'awaiting', 'finish', 'of', '2', 'more', 'threads\\\\n\",']\n",
      "['\"2017-08-09', '17:04:01,283', ':', 'INFO', ':', 'worker', 'thread', 'finished;', 'awaiting', 'finish', 'of', '1', 'more', 'threads\\\\n\",']\n",
      "['\"2017-08-09', '17:04:01,284', ':', 'INFO', ':', 'worker', 'thread', 'finished;', 'awaiting', 'finish', 'of', '0', 'more', 'threads\\\\n\",']\n",
      "['\"2017-08-09', '17:04:01,286', ':', 'INFO', ':', 'training', 'on', '4305', 'raw', 'words', '(361', 'effective', 'words)', 'took', '0.0s,', '30573', 'effective', 'words/s\\\\n\",']\n",
      "['\"2017-08-09', '17:04:01,286', ':', 'WARNING', ':', 'under', '10', 'jobs', 'per', 'worker:', 'consider', 'setting', 'a', 'smaller', \"`batch_words'\", 'for', 'smoother', 'alpha', 'decay\\\\n\"']\n",
      "[']']\n",
      "['},']\n",
      "['{']\n",
      "['\"name\":', '\"stdout\",']\n",
      "['\"output_type\":', '\"stream\",']\n",
      "['\"text\":', '[']\n",
      "['\"<__main__.MySentences', 'object', 'at', '0x000001D7B784B6A0>\\\\n\"']\n",
      "[']']\n",
      "['}']\n",
      "['],']\n",
      "['\"source\":', '[']\n",
      "['\"import', 'os\\\\n\",']\n",
      "['\"class', 'MySentences(object):\\\\n\",']\n",
      "['\"', 'def', '__init__(self,', 'dirname):\\\\n\",']\n",
      "['\"', 'self.dirname', '=', 'dirname\\\\n\",']\n",
      "['\"', '\\\\n\",']\n",
      "['\"', 'def', '__iter__(self):\\\\n\",']\n",
      "['\"', 'for', 'fname', 'in', 'os.listdir(self.dirname):\\\\n\",']\n",
      "['\"', 'try:\\\\n\",']\n",
      "['\"', 'for', 'line', 'in', 'open(os.path.join(self.dirname,', 'fname)):\\\\n\",']\n",
      "['\"', 'yield', 'line.split()\\\\n\",']\n",
      "['\"', 'except:\\\\n\",']\n",
      "['\"', 'pass\\\\n\",']\n",
      "['\"sentences=', 'MySentences(os.getcwd())', '#', 'a', 'memory-friendly', 'iterator\\\\n\",']\n",
      "['\"print(sentences)\\\\n\",']\n",
      "['\"model', '=', 'gensim.models.Word2Vec(sentences)\"']\n",
      "[']']\n",
      "['},']\n",
      "['{']\n",
      "['\"cell_type\":', '\"code\",']\n",
      "['\"execution_count\":', '5,']\n",
      "['\"metadata\":', '{']\n",
      "['\"collapsed\":', 'false']\n",
      "['},']\n",
      "['\"outputs\":', '[']\n",
      "['{']\n",
      "['\"name\":', '\"stderr\",']\n",
      "['\"output_type\":', '\"stream\",']\n",
      "['\"text\":', '[']\n",
      "['\"2017-08-09', '17:07:24,409', ':', 'INFO', ':', 'collecting', 'all', 'words', 'and', 'their', 'counts\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,410', ':', 'WARNING', ':', 'Each', \"'sentences'\", 'item', 'should', 'be', 'a', 'list', 'of', 'words', '(usually', 'unicode', 'strings).First', 'item', 'here', 'is', 'instead', 'plain', '<class', '\\'str\\'>.\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,411', ':', 'INFO', ':', 'PROGRESS:', 'at', 'sentence', '#0,', 'processed', '0', 'words,', 'keeping', '0', 'word', 'types\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,412', ':', 'INFO', ':', 'collected', '5', 'word', 'types', 'from', 'a', 'corpus', 'of', '8', 'raw', 'words', 'and', '8', 'sentences\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,413', ':', 'INFO', ':', 'Loading', 'a', 'fresh', 'vocabulary\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,414', ':', 'INFO', ':', 'min_count=1', 'retains', '5', 'unique', 'words', '(100%', 'of', 'original', '5,', 'drops', '0)\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,414', ':', 'INFO', ':', 'min_count=1', 'leaves', '8', 'word', 'corpus', '(100%', 'of', 'original', '8,', 'drops', '0)\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,416', ':', 'INFO', ':', 'deleting', 'the', 'raw', 'counts', 'dictionary', 'of', '5', 'items\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,416', ':', 'INFO', ':', 'sample=0.001', 'downsamples', '5', 'most-common', 'words\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,417', ':', 'INFO', ':', 'downsampling', 'leaves', 'estimated', '0', 'word', 'corpus', '(7.2%', 'of', 'prior', '8)\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,418', ':', 'INFO', ':', 'estimated', 'required', 'memory', 'for', '5', 'words', 'and', '100', 'dimensions:', '6500', 'bytes\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,419', ':', 'INFO', ':', 'resetting', 'layer', 'weights\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,421', ':', 'INFO', ':', 'training', 'model', 'with', '3', 'workers', 'on', '5', 'vocabulary', 'and', '100', 'features,', 'using', 'sg=0', 'hs=0', 'sample=0.001', 'negative=5', 'window=5\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,426', ':', 'INFO', ':', 'worker', 'thread', 'finished;', 'awaiting', 'finish', 'of', '2', 'more', 'threads\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,427', ':', 'INFO', ':', 'worker', 'thread', 'finished;', 'awaiting', 'finish', 'of', '1', 'more', 'threads\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,428', ':', 'INFO', ':', 'worker', 'thread', 'finished;', 'awaiting', 'finish', 'of', '0', 'more', 'threads\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,429', ':', 'INFO', ':', 'training', 'on', '40', 'raw', 'words', '(3', 'effective', 'words)', 'took', '0.0s,', '785', 'effective', 'words/s\\\\n\",']\n",
      "['\"2017-08-09', '17:07:24,431', ':', 'WARNING', ':', 'under', '10', 'jobs', 'per', 'worker:', 'consider', 'setting', 'a', 'smaller', \"`batch_words'\", 'for', 'smoother', 'alpha', 'decay\\\\n\"']\n",
      "[']']\n",
      "['},']\n",
      "['{']\n",
      "['\"name\":', '\"stdout\",']\n",
      "['\"output_type\":', '\"stream\",']\n",
      "['\"text\":', '[']\n",
      "['\"<__main__.MySentences', 'object', 'at', '0x000001D7B7850128>\\\\n\"']\n",
      "[']']\n",
      "['}']\n",
      "['],']\n",
      "['\"source\":', '[']\n",
      "['\"sentences=', 'MySentences(os.getcwd())', '#', 'a', 'memory-friendly', 'iterator\\\\n\",']\n",
      "['\"print(sentences)\\\\n\",']\n",
      "['\"model', '=', 'gensim.models.Word2Vec(\\\\\"test.txt\\\\\",min_count=1)\"']\n",
      "[']']\n",
      "['},']\n",
      "['{']\n",
      "['\"cell_type\":', '\"code\",']\n",
      "['\"execution_count\":', '6,']\n",
      "['\"metadata\":', '{']\n",
      "['\"collapsed\":', 'false']\n",
      "['},']\n",
      "['\"outputs\":', '[']\n",
      "['{']\n",
      "['\"ename\":', '\"ValueError\",']\n",
      "['\"evalue\":', '\"missing', 'section', 'header', 'before', 'line', '#0', 'in', 'test.txt\",']\n",
      "['\"output_type\":', '\"error\",']\n",
      "['\"traceback\":', '[']\n",
      "['\"\\\\u001b[0;31m---------------------------------------------------------------------------\\\\u001b[0m\",']\n",
      "['\"\\\\u001b[0;31mValueError\\\\u001b[0m', 'Traceback', '(most', 'recent', 'call', 'last)\",']\n",
      "['\"\\\\u001b[0;32m<ipython-input-6-49a5c0830555>\\\\u001b[0m', 'in', '\\\\u001b[0;36m<module>\\\\u001b[0;34m()\\\\u001b[0m\\\\n\\\\u001b[0;32m---->', '1\\\\u001b[0;31m', '\\\\u001b[0mmodel\\\\u001b[0m\\\\u001b[1;33m.\\\\u001b[0m\\\\u001b[0maccuracy\\\\u001b[0m\\\\u001b[1;33m(\\\\u001b[0m\\\\u001b[1;34m\\'test.txt\\'\\\\u001b[0m\\\\u001b[1;33m)\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[0m\",']\n",
      "['\"\\\\u001b[0;32mC:\\\\\\\\Users\\\\\\\\TH-home\\\\\\\\AppData\\\\\\\\Local\\\\\\\\conda\\\\\\\\conda\\\\\\\\envs\\\\\\\\my_root\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\gensim\\\\\\\\models\\\\\\\\word2vec.py\\\\u001b[0m', 'in', '\\\\u001b[0;36maccuracy\\\\u001b[0;34m(self,', 'questions,', 'restrict_vocab,', 'most_similar,', 'case_insensitive)\\\\u001b[0m\\\\n\\\\u001b[1;32m', '1358\\\\u001b[0m', '\\\\u001b[1;32mdef\\\\u001b[0m', '\\\\u001b[0maccuracy\\\\u001b[0m\\\\u001b[1;33m(\\\\u001b[0m\\\\u001b[0mself\\\\u001b[0m\\\\u001b[1;33m,\\\\u001b[0m', '\\\\u001b[0mquestions\\\\u001b[0m\\\\u001b[1;33m,\\\\u001b[0m', '\\\\u001b[0mrestrict_vocab\\\\u001b[0m\\\\u001b[1;33m=\\\\u001b[0m\\\\u001b[1;36m30000\\\\u001b[0m\\\\u001b[1;33m,\\\\u001b[0m', '\\\\u001b[0mmost_similar\\\\u001b[0m\\\\u001b[1;33m=\\\\u001b[0m\\\\u001b[1;32mNone\\\\u001b[0m\\\\u001b[1;33m,\\\\u001b[0m', '\\\\u001b[0mcase_insensitive\\\\u001b[0m\\\\u001b[1;33m=\\\\u001b[0m\\\\u001b[1;32mTrue\\\\u001b[0m\\\\u001b[1;33m)\\\\u001b[0m\\\\u001b[1;33m:\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[1;32m', '1359\\\\u001b[0m', '\\\\u001b[0mmost_similar\\\\u001b[0m', '\\\\u001b[1;33m=\\\\u001b[0m', '\\\\u001b[0mmost_similar\\\\u001b[0m', '\\\\u001b[1;32mor\\\\u001b[0m', '\\\\u001b[0mKeyedVectors\\\\u001b[0m\\\\u001b[1;33m.\\\\u001b[0m\\\\u001b[0mmost_similar\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[0;32m->', '1360\\\\u001b[0;31m', '\\\\u001b[1;32mreturn\\\\u001b[0m', '\\\\u001b[0mself\\\\u001b[0m\\\\u001b[1;33m.\\\\u001b[0m\\\\u001b[0mwv\\\\u001b[0m\\\\u001b[1;33m.\\\\u001b[0m\\\\u001b[0maccuracy\\\\u001b[0m\\\\u001b[1;33m(\\\\u001b[0m\\\\u001b[0mquestions\\\\u001b[0m\\\\u001b[1;33m,\\\\u001b[0m', '\\\\u001b[0mrestrict_vocab\\\\u001b[0m\\\\u001b[1;33m,\\\\u001b[0m', '\\\\u001b[0mmost_similar\\\\u001b[0m\\\\u001b[1;33m,\\\\u001b[0m', '\\\\u001b[0mcase_insensitive\\\\u001b[0m\\\\u001b[1;33m)\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[0m\\\\u001b[1;32m', '1361\\\\u001b[0m', '\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[1;32m', '1362\\\\u001b[0m', '\\\\u001b[1;33m@\\\\u001b[0m\\\\u001b[0mstaticmethod\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\",']\n",
      "['\"\\\\u001b[0;32mC:\\\\\\\\Users\\\\\\\\TH-home\\\\\\\\AppData\\\\\\\\Local\\\\\\\\conda\\\\\\\\conda\\\\\\\\envs\\\\\\\\my_root\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\gensim\\\\\\\\models\\\\\\\\keyedvectors.py\\\\u001b[0m', 'in', '\\\\u001b[0;36maccuracy\\\\u001b[0;34m(self,', 'questions,', 'restrict_vocab,', 'most_similar,', 'case_insensitive)\\\\u001b[0m\\\\n\\\\u001b[1;32m', '677\\\\u001b[0m', '\\\\u001b[1;32melse\\\\u001b[0m\\\\u001b[1;33m:\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[1;32m', '678\\\\u001b[0m', '\\\\u001b[1;32mif\\\\u001b[0m', '\\\\u001b[1;32mnot\\\\u001b[0m', '\\\\u001b[0msection\\\\u001b[0m\\\\u001b[1;33m:\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[0;32m-->', '679\\\\u001b[0;31m', '\\\\u001b[1;32mraise\\\\u001b[0m', '\\\\u001b[0mValueError\\\\u001b[0m\\\\u001b[1;33m(\\\\u001b[0m\\\\u001b[1;34m\\\\\"missing', 'section', 'header', 'before', 'line', '#%i', 'in', '%s\\\\\"\\\\u001b[0m', '\\\\u001b[1;33m%\\\\u001b[0m', '\\\\u001b[1;33m(\\\\u001b[0m\\\\u001b[0mline_no\\\\u001b[0m\\\\u001b[1;33m,\\\\u001b[0m', '\\\\u001b[0mquestions\\\\u001b[0m\\\\u001b[1;33m)\\\\u001b[0m\\\\u001b[1;33m)\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[0m\\\\u001b[1;32m', '680\\\\u001b[0m', '\\\\u001b[1;32mtry\\\\u001b[0m\\\\u001b[1;33m:\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[1;32m', '681\\\\u001b[0m', '\\\\u001b[1;32mif\\\\u001b[0m', '\\\\u001b[0mcase_insensitive\\\\u001b[0m\\\\u001b[1;33m:\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\",']\n",
      "['\"\\\\u001b[0;31mValueError\\\\u001b[0m:', 'missing', 'section', 'header', 'before', 'line', '#0', 'in', 'test.txt\"']\n",
      "[']']\n",
      "['}']\n",
      "['],']\n",
      "['\"source\":', '[']\n",
      "['\"model.accuracy(\\'test.txt\\')\"']\n",
      "[']']\n",
      "['},']\n",
      "['{']\n",
      "['\"cell_type\":', '\"code\",']\n",
      "['\"execution_count\":', '8,']\n",
      "['\"metadata\":', '{']\n",
      "['\"collapsed\":', 'false']\n",
      "['},']\n",
      "['\"outputs\":', '[']\n",
      "['{']\n",
      "['\"name\":', '\"stderr\",']\n",
      "['\"output_type\":', '\"stream\",']\n",
      "['\"text\":', '[']\n",
      "['\"2017-08-09', '17:10:53,647', ':', 'INFO', ':', 'saving', 'Word2Vec', 'object', 'under', 'mymodel,', 'separately', 'None\\\\n\",']\n",
      "['\"2017-08-09', '17:10:53,649', ':', 'INFO', ':', 'not', 'storing', 'attribute', 'syn0norm\\\\n\",']\n",
      "['\"2017-08-09', '17:10:53,650', ':', 'INFO', ':', 'not', 'storing', 'attribute', 'cum_table\\\\n\",']\n",
      "['\"2017-08-09', '17:10:53,655', ':', 'INFO', ':', 'saved', 'mymodel\\\\n\",']\n",
      "['\"2017-08-09', '17:10:53,657', ':', 'INFO', ':', 'loading', 'Word2Vec', 'object', 'from', 'mymodel\\\\n\",']\n",
      "['\"2017-08-09', '17:10:53,659', ':', 'INFO', ':', 'loading', 'wv', 'recursively', 'from', 'mymodel.wv.*', 'with', 'mmap=None\\\\n\",']\n",
      "['\"2017-08-09', '17:10:53,660', ':', 'INFO', ':', 'setting', 'ignored', 'attribute', 'syn0norm', 'to', 'None\\\\n\",']\n",
      "['\"2017-08-09', '17:10:53,662', ':', 'INFO', ':', 'setting', 'ignored', 'attribute', 'cum_table', 'to', 'None\\\\n\",']\n",
      "['\"2017-08-09', '17:10:53,663', ':', 'INFO', ':', 'loaded', 'mymodel\\\\n\"']\n",
      "[']']\n",
      "['}']\n",
      "['],']\n",
      "['\"source\":', '[']\n",
      "['\"model.save(\\'mymodel\\')\\\\n\",']\n",
      "['\"new_model', '=', 'gensim.models.Word2Vec.load(\\'mymodel\\')\\\\n\",']\n",
      "['\"#also', 'can\\\\n\",']\n",
      "['\"#model', '=', \"Word2Vec.load_word2vec_format('/tmp/vectors.txt',\", 'binary=False)\"']\n",
      "[']']\n",
      "['},']\n",
      "['{']\n",
      "['\"cell_type\":', '\"code\",']\n",
      "['\"execution_count\":', '9,']\n",
      "['\"metadata\":', '{']\n",
      "['\"collapsed\":', 'true']\n",
      "['},']\n",
      "['\"outputs\":', '[],']\n",
      "['\"source\":', '[']\n",
      "['\"##', 'add', 'train\\\\n\",']\n",
      "['\"#model.train(more_sentences)\"']\n",
      "[']']\n",
      "['},']\n",
      "['{']\n",
      "['\"cell_type\":', '\"code\",']\n",
      "['\"execution_count\":', 'null,']\n",
      "['\"metadata\":', '{']\n",
      "['\"collapsed\":', 'true']\n",
      "['},']\n",
      "['\"outputs\":', '[],']\n",
      "['\"source\":', '[']\n",
      "['\"model.most_similar(positive=[\\'woman\\',', \"'king'],\", \"negative=['man'],\", 'topn=1)\\\\n\",']\n",
      "['\"model.doesnt_match(\\\\\"breakfast', 'cereal', 'dinner', 'lunch\\\\\";.split())\\\\n\",']\n",
      "['\"#', 'get', 'similarity\\\\n\",']\n",
      "['\"model.similarity(\\'woman\\',', '\\'man\\')\\\\n\",']\n",
      "['\"#', 'get', 'vector\\\\n\",']\n",
      "['\"model[\\'computer\\']\"']\n",
      "[']']\n",
      "['},']\n",
      "['{']\n",
      "['\"cell_type\":', '\"code\",']\n",
      "['\"execution_count\":', '10,']\n",
      "['\"metadata\":', '{']\n",
      "['\"collapsed\":', 'false']\n",
      "['},']\n",
      "['\"outputs\":', '[']\n",
      "['{']\n",
      "['\"name\":', '\"stdout\",']\n",
      "['\"output_type\":', '\"stream\",']\n",
      "['\"text\":', '[']\n",
      "['\"<__main__.MySentences', 'object', 'at', '0x000001D7B7850128>\\\\n\"']\n",
      "[']']\n",
      "['}']\n",
      "['],']\n",
      "['\"source\":', '[']\n",
      "['\"for', 'i', 'in', 'sentences:\\\\n\",']\n",
      "['\"', 'print()\"']\n",
      "[']']\n",
      "['},']\n",
      "['{']\n",
      "['\"cell_type\":', '\"code\",']\n",
      "['\"execution_count\":', 'null,']\n",
      "['\"metadata\":', '{']\n",
      "['\"collapsed\":', 'true']\n",
      "['},']\n",
      "['\"outputs\":', '[],']\n",
      "['\"source\":', '[]']\n",
      "['}']\n",
      "['],']\n",
      "['\"metadata\":', '{']\n",
      "['\"kernelspec\":', '{']\n",
      "['\"display_name\":', '\"Python', '3\",']\n",
      "['\"language\":', '\"python\",']\n",
      "['\"name\":', '\"python3\"']\n",
      "['},']\n",
      "['\"language_info\":', '{']\n",
      "['\"codemirror_mode\":', '{']\n",
      "['\"name\":', '\"ipython\",']\n",
      "['\"version\":', '3']\n",
      "['},']\n",
      "['\"file_extension\":', '\".py\",']\n",
      "['\"mimetype\":', '\"text/x-python\",']\n",
      "['\"name\":', '\"python\",']\n",
      "['\"nbconvert_exporter\":', '\"python\",']\n",
      "['\"pygments_lexer\":', '\"ipython3\",']\n",
      "['\"version\":', '\"3.6.0\"']\n",
      "['}']\n",
      "['},']\n",
      "['\"nbformat\":', '4,']\n",
      "['\"nbformat_minor\":', '2']\n",
      "['}']\n"
     ]
    }
   ],
   "source": [
    "for i in sentences:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-09 18:25:41,480 : INFO : collecting all words and their counts\n",
      "2017-08-09 18:25:41,485 : WARNING : Each 'sentences' item should be a list of words (usually unicode strings).First item here is instead plain <class 'str'>.\n",
      "2017-08-09 18:25:41,486 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-08-09 18:25:41,487 : INFO : collected 5 word types from a corpus of 8 raw words and 8 sentences\n",
      "2017-08-09 18:25:41,488 : INFO : Loading a fresh vocabulary\n",
      "2017-08-09 18:25:41,489 : INFO : min_count=1 retains 5 unique words (100% of original 5, drops 0)\n",
      "2017-08-09 18:25:41,490 : INFO : min_count=1 leaves 8 word corpus (100% of original 8, drops 0)\n",
      "2017-08-09 18:25:41,492 : INFO : deleting the raw counts dictionary of 5 items\n",
      "2017-08-09 18:25:41,493 : INFO : sample=0.001 downsamples 5 most-common words\n",
      "2017-08-09 18:25:41,494 : INFO : downsampling leaves estimated 0 word corpus (7.2% of prior 8)\n",
      "2017-08-09 18:25:41,496 : INFO : estimated required memory for 5 words and 100 dimensions: 6500 bytes\n",
      "2017-08-09 18:25:41,499 : INFO : resetting layer weights\n",
      "2017-08-09 18:25:41,503 : INFO : training model with 3 workers on 5 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-08-09 18:25:41,511 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-08-09 18:25:41,512 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-08-09 18:25:41,513 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-08-09 18:25:41,514 : INFO : training on 40 raw words (3 effective words) took 0.0s, 746 effective words/s\n",
      "2017-08-09 18:25:41,516 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(\"test.txt\",min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'asdf' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ab2a11c8bbbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'asdf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\TH-home\\AppData\\Local\\conda\\conda\\envs\\my_root\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \u001b[0mRefer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[1;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \"\"\"\n\u001b[0;32m-> 1281\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\TH-home\\AppData\\Local\\conda\\conda\\envs\\my_root\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[1;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\TH-home\\AppData\\Local\\conda\\conda\\envs\\my_root\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'asdf' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model['asdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'cp949' codec can't decode byte 0xed in position 44: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c8a813ac203d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'cp949' codec can't decode byte 0xed in position 44: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "f = open(\"pos_list.txt\", 'r')\n",
    "i=0\n",
    "while True:\n",
    "    if i>5:\n",
    "        break\n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    print(line)\n",
    "    i+=1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-09 19:58:10,272 : INFO : loading Word2Vec object from word2vec_test_pychar_model\n",
      "2017-08-09 19:58:11,450 : INFO : loading wv recursively from word2vec_test_pychar_model.wv.* with mmap=None\n",
      "2017-08-09 19:58:11,451 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-08-09 19:58:11,452 : INFO : setting ignored attribute cum_table to None\n",
      "2017-08-09 19:58:11,453 : INFO : loaded word2vec_test_pychar_model\n"
     ]
    }
   ],
   "source": [
    "new_model = gensim.models.Word2Vec.load('word2vec_test_pychar_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15277584, -0.25172231,  0.47172719,  0.70139146, -0.82663673,\n",
       "       -0.30099526, -0.66833544,  1.00088871,  0.38996422,  0.21311578,\n",
       "        0.08139013,  0.60529   ,  0.18751983, -0.28436312,  0.26720992,\n",
       "        0.50570774,  0.15860294,  0.33529869,  0.45613885, -1.38765168,\n",
       "        1.08886242,  0.58565807, -0.6358211 ,  0.4244971 , -0.04196192,\n",
       "       -1.14449453, -0.14326268,  0.01566602, -1.31420171, -0.39065444,\n",
       "        0.33447617, -0.69154996, -0.02378082, -0.50016028,  1.07452548,\n",
       "        0.35946202, -1.01666403, -0.08754063,  0.57454848, -0.02983022,\n",
       "       -0.46291101,  0.33821109, -0.12763557, -0.38395265,  0.62161493,\n",
       "       -0.48049963,  0.24418563,  0.05455471,  0.68410736,  0.62754691,\n",
       "       -0.25539711, -0.31860197, -0.51829571, -1.39233983, -0.65187502,\n",
       "       -0.2269502 ,  0.10453812,  0.32774013,  0.3382453 , -0.62023938,\n",
       "        0.82399929,  0.22118048,  0.2428993 , -0.24189056, -0.3187713 ,\n",
       "        0.47503397,  2.57405591,  1.11982608,  0.42651469, -0.01283532,\n",
       "        0.16137072, -1.16217768,  0.79036129, -0.41507122,  0.4042199 ,\n",
       "       -0.35972983,  0.07594328,  0.31853163,  0.01012116,  0.90155965,\n",
       "       -0.21139579,  0.46785125, -0.08345011, -0.46688145,  0.27106932,\n",
       "        0.09036382,  0.60357285,  0.90212983,  0.45677602,  0.97398579,\n",
       "        0.64196432, -0.15726794, -0.77770203,  0.66377169,  1.12019205,\n",
       "       -0.75049901, -0.32654229, -0.77185011, -0.11884233, -0.73866445], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.wv['선보']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
